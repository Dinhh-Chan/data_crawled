{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  requests\n",
    "from bs4 import BeautifulSoup \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.iec.ch/news-blogs', 'https://www.iec.ch/press-releases', 'https://www.iec.ch/subscribe', 'https://www.iec.ch/events', 'https://www.iec.ch/committee-meetings', 'https://www.iec.ch/news-resources/reference-material', 'https://www.iec.ch/what-we-do/facts-figures', 'https://www.iec.ch/resource-area', 'https://www.iec.ch/basecamp']\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.iec.ch/news-resources\"\n",
    "BASE_URL = \"https://www.iec.ch\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text , \"html.parser\")\n",
    "a_tag = soup.find(\"a\", string= \"News & resources\")\n",
    "if a_tag:\n",
    "    li_tag = a_tag.find_parent(\"li\")\n",
    "ul_tag = li_tag.find(\"ul\", class_ = \"dropdown-menu\")\n",
    "a_item_list = ul_tag.find_all(\"a\")\n",
    "item_list = []\n",
    "for a_item in a_item_list :\n",
    "    item_list.append(BASE_URL + a_item.get(\"href\"))\n",
    "print(item_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.iec.ch/blog', 'https://www.iec.ch/press-releases', 'https://www.iec.ch/blog?categories=372', 'https://etech.iec.ch/', 'https://www.iec.ch/smb-communique', 'https://webstore.iec.ch/justpublished?Select=past2week', 'https://www.iec.ch/standards-development/new-projects']\n"
     ]
    }
   ],
   "source": [
    "# news and blogs \n",
    "#find all card item \n",
    "URL = \"https://www.iec.ch/news-blogs\"\n",
    "response = requests.get(URL)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "div_tags = soup.find_all(\"div\", class_= \"section-card-item-wrapper\")\n",
    "list_href = []\n",
    "for div_tag in div_tags :\n",
    "    if \"https\" not in div_tag.find(\"a\").get(\"href\"):\n",
    "        list_href.append(\"https://www.iec.ch\"+ div_tag.find(\"a\").get(\"href\"))\n",
    "    else :\n",
    "        list_href.append(div_tag.find(\"a\").get(\"href\"))\n",
    "print(list_href)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 1176 blog posts.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "url = \"https://www.iec.ch/blog\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Get the last page number\n",
    "last_page_tag = soup.find(\"a\", rel=\"last\")\n",
    "if last_page_tag:\n",
    "    last_page = int(last_page_tag.get(\"href\").split(\"=\")[1])\n",
    "else:\n",
    "    last_page = 1  # If no pagination, default to 1\n",
    "\n",
    "# Base URL and list to store blog information\n",
    "base_url = \"https://www.iec.ch\"\n",
    "link_and_infor = []\n",
    "\n",
    "# Loop through all pages\n",
    "for page in range(last_page):\n",
    "    link = url + \"?page=\" + str(page)\n",
    "    response = requests.get(link)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    div_contents = soup.find_all(\"div\", class_=\"blog-article-div-content\")\n",
    "    \n",
    "    for div_content in div_contents:\n",
    "        tag_arr = div_content.find_all(\"div\", class_=\"blog-article-div-categorie\")\n",
    "        tag = tag.text.strip() if tag else \"No tag\"\n",
    "        \n",
    "        h2 = div_content.find(\"h2\")\n",
    "        title = h2.text.strip() if h2 else \"No title\"\n",
    "        link = base_url + h2.find(\"a\").get(\"href\") if h2 and h2.find(\"a\") else \"No link\"\n",
    "        \n",
    "        published_day = div_content.find(\"div\", class_=\"blog-article-date-author\")\n",
    "        published_day = published_day.text.strip() if published_day else \"No date\"\n",
    "        \n",
    "        abstract = div_content.find(\"p\", class_=\"blog-article-information__description\")\n",
    "        abstract = abstract.text.strip() if abstract else \"No abstract\"\n",
    "        \n",
    "        # Fetch content from the blog page\n",
    "        response = requests.get(link)\n",
    "        content_soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        content = content_soup.find(\"div\", class_=\"blog-article-description\")\n",
    "        content = content.text.strip() if content else \"No content\"\n",
    "        \n",
    "        # Store data\n",
    "        data_infor = {\n",
    "            \"tag\": tag,\n",
    "            \"title\": title,\n",
    "            \"link\": link,\n",
    "            \"published_day\": published_day,\n",
    "            \"abstract\": abstract,\n",
    "            \"content\": content\n",
    "        }\n",
    "        link_and_infor.append(data_infor)\n",
    "\n",
    "# Save data to JSON\n",
    "with open(\"iec_blog.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(link_and_infor, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Scraped {len(link_and_infor)} blog posts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iec \n",
    "url = \"https://www.iec.ch/press-releases\"\n",
    "response = requests.get(url)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
